{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所需库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树分类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''决策树分类模型\n",
    "    先定义树节点类DecisonNode,再定义决策树类DecisionTreeClassifier\n",
    "    使用信息增益infomation gain,建立ID3算法\n",
    "'''\n",
    "class DecisionNode:\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
    "        # 对于决策节点\n",
    "        self.feature_index = feature_index  #决策节点的特征的索引\n",
    "        self.threshold = threshold          #决策节点的阈值\n",
    "        self.left = left                    #决策节点的左孩子\n",
    "        self.right = right                  #决策节点的右孩子\n",
    "        self.info_gain = info_gain          #信息增益\n",
    "        \n",
    "        # 对于叶节点\n",
    "        self.value = value                  #叶节点的值\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self,min_samples_split=2, max_depth=2) -> None:\n",
    "        # 初始化树的根节点\n",
    "        self.root=None\n",
    "        # 停止条件\n",
    "        self.min_samples_split=min_samples_split    #最小分裂样本\n",
    "        self.max_depth=max_depth                    #决策树最大深度\n",
    "\n",
    "    '''\n",
    "    训练模型\n",
    "    X:样本数据中的变量\n",
    "    y:样本数据中的类别\n",
    "    '''   \n",
    "    def fit(self, X, y):\n",
    "        # 训练模型\n",
    "        self.root = self.build_tree(X, y)    \n",
    "\n",
    "    '''\n",
    "    计算信息熵\n",
    "    y:样本数据中的类别结果\n",
    "    '''    \n",
    "    def entropy(self, y):\n",
    "        class_labels = np.unique(y)                 #样本有多少类别\n",
    "        entropy = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y == cls]) / len(y)       #每一类别的比例\n",
    "            entropy += -p_cls * np.log2(p_cls)      #信息熵\n",
    "        return entropy\n",
    "    \n",
    "    '''\n",
    "    对样本数据进行分裂\n",
    "    dataset:样本数据(X,Y)\n",
    "    ''' \n",
    "    def split(self, X,y, feature_index, threshold):\n",
    "        #根据阈值分割数据\n",
    "        left_idx = X[:, feature_index] <= threshold\n",
    "        right_idx = X[:, feature_index] > threshold\n",
    "        return {'left': (X[left_idx], y[left_idx]), 'right': (X[right_idx], y[right_idx])}\n",
    "\n",
    "    '''\n",
    "    计算信息增益\n",
    "    '''   \n",
    "    def information_gain(self, parent, l_child, r_child):\n",
    "        weight_l = len(l_child) / len(parent)               #左孩子占比\n",
    "        weight_r = len(r_child) / len(parent)               #右孩子占比\n",
    "        gain = self.entropy(parent) - (weight_l*self.entropy(l_child) + weight_r*self.entropy(r_child))\n",
    "        return gain\n",
    "    \n",
    "    '''\n",
    "    求最佳分割\n",
    "    '''   \n",
    "    def get_best_split(self, X, y, num_features):\n",
    "        # 寻找最佳分割点\n",
    "        best_split = {}\n",
    "        # 初始化最大信息增益为负无穷大\n",
    "        max_info_gain = -float('inf')\n",
    "        # 遍历所有特征\n",
    "        for feature_index in range(num_features):\n",
    "            feature_values = X[:, feature_index]\n",
    "            thresholds = np.unique(feature_values)\n",
    "            # 遍历所有阈值\n",
    "            for threshold in thresholds:\n",
    "                # 数据分裂\n",
    "                datasets = self.split(X, y, feature_index, threshold)\n",
    "                # 如果\n",
    "                if len(datasets['left'][1]) > 0 and len(datasets['right'][1]) > 0:\n",
    "                # 计算信息增益\n",
    "                    curr_info_gain = self.information_gain(y, datasets['left'][1], datasets['right'][1])\n",
    "                    if curr_info_gain  > max_info_gain:\n",
    "                        max_info_gain = curr_info_gain \n",
    "                        best_split = {'feature_index': feature_index, 'threshold': threshold, 'datasets': datasets,\n",
    "                                      'info_gain':curr_info_gain, 'value': None}\n",
    "        return best_split\n",
    "\n",
    "    '''\n",
    "    递归构建决策树\n",
    "    '''   \n",
    "    def build_tree(self, X, y, current_depth=0):\n",
    "        # 样本数和特征数\n",
    "        num_samples, num_features = X.shape\n",
    "        \n",
    "        #如果样本数大于最小分裂数，并且当前深度比最大深度小，则往下建树\n",
    "        if num_samples >= self.min_samples_split and current_depth <= self.max_depth:\n",
    "            \n",
    "            best_split = self.get_best_split(X, y, num_features)\n",
    "\n",
    "            # 如果信息增益大于0说明还能分，小于0说明不能分了，则为叶子节点\n",
    "            if best_split['info_gain'] >0:\n",
    "                left_subtree = self.build_tree(*best_split['datasets']['left'], current_depth+1)\n",
    "                right_subtree = self.build_tree(*best_split['datasets']['right'], current_depth+1)\n",
    "                \n",
    "                return DecisionNode(best_split['feature_index'], best_split['threshold'], left_subtree, right_subtree,best_split['info_gain'])\n",
    "            \n",
    "                \n",
    "\n",
    "        leaf_value = self.calculate_leaf_value(y)\n",
    "        return DecisionNode(value=leaf_value)  \n",
    "    \n",
    "    def calculate_leaf_value(self, Y):\n",
    "        Y = list(Y)\n",
    "        return max(Y, key=Y.count)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        predictions = [self.make_prediction(x, self.root) for x in X]\n",
    "        return predictions\n",
    "    \n",
    "    def make_prediction(self, x, tree):\n",
    "        if tree.value != None: return tree.value\n",
    "        feature_val = x[tree.feature_index]\n",
    "        if feature_val <= tree.threshold:\n",
    "            return self.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.right)\n",
    "    \n",
    "    def train_test_split(self,X, y, test_size=0.2, random_state=None):\n",
    "        \"\"\"将数据集划分为训练集和测试集\"\"\"\n",
    "        if random_state:\n",
    "            np.random.seed(random_state)\n",
    "        \n",
    "        # 随机打乱索引\n",
    "        indices = np.arange(X.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        # 根据test_size计算测试集大小\n",
    "        test_set_size = int(X.shape[0] * test_size)\n",
    "        \n",
    "        # 划分测试集和训练集\n",
    "        test_indices = indices[:test_set_size]\n",
    "        train_indices = indices[test_set_size:]\n",
    "        \n",
    "        # 划分数据集\n",
    "        X_train = X[train_indices]\n",
    "        X_test = X[test_indices]\n",
    "        y_train = y[train_indices]\n",
    "        y_test = y[test_indices]\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test \n",
    "    \n",
    "    def accuracy_score(self,y_true, y_pred):\n",
    "        \"\"\"计算准确率\"\"\"\n",
    "        correct_predictions = sum(y_pred[i] == y_true[i] for i in range(len(y_true)))\n",
    "        accuracy = correct_predictions / len(y_true)\n",
    "        return accuracy\n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对鸢尾花数据进行训练，使用sklearn库中自带的鸢尾花数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "'''鸢尾花数据集\n",
    "    150个样本,按7:3划分为训练集和测试集\n",
    "    3个类别('Iris-setosa', 'Iris-versicolor', 'Iris-virginica'),\n",
    "    4个属性('sepal length','sepal width','petal length','petal width'),\n",
    "    构建决策树分类模型并测试准确率\n",
    "    呈现训练过程,绘制分类结果,评估模型准确性\n",
    "'''\n",
    "from sklearn.datasets import load_iris\n",
    "# 加载数据集\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "# 分割数据集为训练集和测试集\n",
    "clf=DecisionTreeClassifier(min_samples_split=2, max_depth=3)\n",
    "X_train, X_test, y_train, y_test = clf.train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=np.array(clf.predict(X_test))\n",
    "accuracy = clf.accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对葡萄酒识别数据进行训练，使用sklearn库中自带的葡萄酒识别数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8490566037735849\n"
     ]
    }
   ],
   "source": [
    "'''葡萄酒识别数据集\n",
    "    178个样本,按7:3划分为训练集和测试集\n",
    "    3个类别,\n",
    "    13个属性,\n",
    "    构建决策树分类模型并测试准确率\n",
    "    呈现训练过程,绘制分类结果,评估模型准确性\n",
    "'''\n",
    "from sklearn.datasets import load_wine\n",
    "wine=load_wine()\n",
    "X,y=wine.data,wine.target\n",
    "# 分割数据集为训练集和测试集\n",
    "clf=DecisionTreeClassifier(min_samples_split=2, max_depth=3)\n",
    "X_train, X_test, y_train, y_test = clf.train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=np.array(clf.predict(X_test))\n",
    "accuracy = clf.accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''决策树回归模型\n",
    "    先定义树节点类DecisonNode,再定义决策树类DecisionTreeRegressor\n",
    "    将信息增益改为方差减少量即可\n",
    "'''\n",
    "class DecisionNode:\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, var_reduction=None, value=None):\n",
    "        # 对于决策节点\n",
    "        self.feature_index = feature_index  #决策节点的特征的索引\n",
    "        self.threshold = threshold          #决策节点的阈值\n",
    "        self.left = left                    #决策节点的左孩子\n",
    "        self.right = right                  #决策节点的右孩子\n",
    "        self.var_reduction = var_reduction          #方差减少量\n",
    "        \n",
    "        # 对于叶节点\n",
    "        self.value = value                  #叶节点的值\n",
    "\n",
    "\n",
    "\n",
    "class DecisionTreeRegressor:\n",
    "    def __init__(self,min_samples_split=2, max_depth=3) -> None:\n",
    "        # 初始化树的根节点\n",
    "        self.root=None\n",
    "        # 停止条件\n",
    "        self.min_samples_split=min_samples_split    #最小分裂样本\n",
    "        self.max_depth=max_depth                    #决策树最大深度\n",
    "\n",
    "    '''\n",
    "    训练模型\n",
    "    X:样本数据中的变量\n",
    "    y:样本数据中的类别\n",
    "    '''   \n",
    "    def fit(self, X, y):\n",
    "        # 训练模型\n",
    "        self.root = self.build_tree(X, y)    \n",
    "    \n",
    "    '''\n",
    "    对样本数据进行分裂\n",
    "    dataset:样本数据(X,Y)\n",
    "    ''' \n",
    "    def split(self, X,y, feature_index, threshold):\n",
    "        #根据阈值分割数据\n",
    "        left_idx = X[:, feature_index] <= threshold\n",
    "        right_idx = X[:, feature_index] > threshold\n",
    "        return {'left': (X[left_idx], y[left_idx]), 'right': (X[right_idx], y[right_idx])}\n",
    "\n",
    "    '''\n",
    "    计算方差减少量\n",
    "    '''   \n",
    "    def variance_reduction(self, parent, l_child, r_child):\n",
    "        #计算方差减少量\n",
    "        weight_left = len(l_child) / len(parent)\n",
    "        weight_right = len(r_child) / len(parent)\n",
    "        reduction = np.var(parent) - (weight_left * np.var(l_child) + weight_right * np.var(r_child))\n",
    "        return reduction\n",
    "    \n",
    "    '''\n",
    "    求最佳分割\n",
    "    '''   \n",
    "    def get_best_split(self, X, y, num_features):\n",
    "        # 寻找最佳分割点\n",
    "        best_split = {}\n",
    "        # 初始化最大信息增益为负无穷大\n",
    "        max_var_reduction = -float('inf')\n",
    "        # 遍历所有特征\n",
    "        for feature_index in range(num_features):\n",
    "            feature_values = X[:, feature_index]\n",
    "            thresholds = np.unique(feature_values)\n",
    "            # 遍历所有阈值\n",
    "            for threshold in thresholds:\n",
    "                # 数据分裂\n",
    "                datasets = self.split(X, y, feature_index, threshold)\n",
    "                # 如果\n",
    "                if len(datasets['left'][1]) > 0 and len(datasets['right'][1]) > 0:\n",
    "                # 计算信息增益\n",
    "                    curr_var_reduction = self.variance_reduction(y, datasets['left'][1], datasets['right'][1])\n",
    "                    if curr_var_reduction > max_var_reduction:\n",
    "                        max_var_reduction = curr_var_reduction \n",
    "                        best_split = {'feature_index': feature_index, 'threshold': threshold, 'datasets': datasets,\n",
    "                                      'var_reduction':curr_var_reduction, 'value': None}\n",
    "        return best_split\n",
    "\n",
    "    '''\n",
    "    递归构建决策树\n",
    "    '''   \n",
    "    def build_tree(self, X, y, current_depth=0):\n",
    "        # 样本数和特征数\n",
    "        num_samples, num_features = X.shape\n",
    "        \n",
    "        #如果样本数大于最小分裂数，并且当前深度比最大深度小，则往下建树,不满足条件则为叶子节点\n",
    "        if num_samples >= self.min_samples_split and current_depth <= self.max_depth:\n",
    "            \n",
    "            best_split = self.get_best_split(X, y, num_features)\n",
    "\n",
    "            # 如果信息增益大于0说明还能分，小于0说明不能分了，则为叶子节点\n",
    "            if best_split['var_reduction'] > 0:\n",
    "                left_subtree = self.build_tree(*best_split['datasets']['left'], current_depth+1)\n",
    "                right_subtree = self.build_tree(*best_split['datasets']['right'], current_depth+1)\n",
    "                \n",
    "                return DecisionNode(best_split['feature_index'], best_split['threshold'], \n",
    "                                    left_subtree, right_subtree,best_split['var_reduction'])\n",
    "            \n",
    "        return DecisionNode(value=np.mean(y))  \n",
    "    \n",
    "    \n",
    "        \n",
    "    def predict(self, X):\n",
    "        predictions = [self.make_prediction(x, self.root) for x in X]\n",
    "        return predictions\n",
    "    \n",
    "    def make_prediction(self, x, tree):\n",
    "        if tree.value != None: return tree.value\n",
    "\n",
    "        feature_val = x[tree.feature_index]\n",
    "        if feature_val <= tree.threshold:\n",
    "            return self.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.right)\n",
    "    \n",
    "    def train_test_split(self,X, y, test_size=0.2, random_state=None):\n",
    "        \"\"\"将数据集划分为训练集和测试集\"\"\"\n",
    "        if random_state:\n",
    "            np.random.seed(random_state)\n",
    "        \n",
    "        # 随机打乱索引\n",
    "        indices = np.arange(X.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        # 根据test_size计算测试集大小\n",
    "        test_set_size = int(X.shape[0] * test_size)\n",
    "        \n",
    "        # 划分测试集和训练集\n",
    "        test_indices = indices[:test_set_size]\n",
    "        train_indices = indices[test_set_size:]\n",
    "        \n",
    "        # 划分数据集\n",
    "        X_train = X[train_indices]\n",
    "        X_test = X[test_indices]\n",
    "        y_train = y[train_indices]\n",
    "        y_test = y[test_indices]\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对波士顿房价预测数据进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²分数: 0.7660068638828825\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "#读取房价数据集\n",
    "\n",
    "raw_df=pd.read_csv(r'data/housing.csv',sep=\"\\s+\",header=None)\n",
    "data = raw_df.values[:,:13]\n",
    "target = raw_df.values[:, 13]\n",
    "X,y=data,target   \n",
    "# 分割数据集为训练集和测试集\n",
    "model=DecisionTreeRegressor(min_samples_split=2, max_depth=3)\n",
    "X_train, X_test, y_train, y_test = model.train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=np.array(model.predict(X_test))\n",
    "# 计算R²分数\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R²分数: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对房地产估计预测数据进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²分数: 0.6790198690514948\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "real_estate_valuation = fetch_ucirepo(id=477) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = real_estate_valuation.data.features \n",
    "y = real_estate_valuation.data.targets \n",
    "X=np.array(X)\n",
    "X=X[:,1:]\n",
    "y=np.array(y)\n",
    "\n",
    "#分割数据集为训练集和测试集\n",
    "model=DecisionTreeRegressor(min_samples_split=2, max_depth=3)\n",
    "X_train, X_test, y_train, y_test = model.train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=np.array(model.predict(X_test))\n",
    "\n",
    "y_pred=[int(item) for item in y_pred]\n",
    "# 计算R²分数\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f'R²分数: {r2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
