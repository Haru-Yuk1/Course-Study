1.1 表1.1中若只包含编号为1和4的两个样例，试给出相应的版本空间。
------------------------------------

答：若表1.1只含编号为1和4的两个样例，则数据集如下

表 1.1 西瓜数据集

<table data-draft-node="block" data-draft-type="table" data-size="normal" data-row-style="normal"><tbody><tr><td>编号</td><td>色泽</td><td>根蒂</td><td>敲声</td><td>好瓜</td></tr><tr><td>1</td><td>青绿</td><td>蜷缩</td><td>浊响</td><td>是</td></tr><tr><td>4</td><td>乌黑</td><td>稍蜷</td><td>沉闷</td><td>否</td></tr></tbody></table>

从一般到特殊或是从特殊到一般对整个假设空间进行搜索，删除与正例1不一致的假设，或与反例4一致的假设，最终得到版本空间为：

1.（色泽＝青绿）∧（根蒂＝ ∗ ）∧（敲声＝ ∗ ）

2.（色泽＝ ∗ ）∧（根蒂＝蜷缩）∧（敲声＝ ∗ ）

3.（色泽＝ ∗ ）∧（根蒂＝ ∗ ）∧（敲声＝浊响）

4.（色泽＝青绿）∧（根蒂＝蜷缩）∧（敲声＝ ∗ ）

5.（色泽＝青绿）∧（根蒂＝ ∗ ）∧（敲声＝浊响）

6.（色泽＝ ∗ ）∧（根蒂＝蜷缩）∧（敲声＝浊响）

7.（色泽＝青绿）∧（根蒂＝蜷缩）∧（敲声＝浊响）

<img src="https://pic4.zhimg.com/v2-9d6574a67c633d2905fe040a4e9ad17b\_b.jpg" data-caption="" data-size="normal" data-rawwidth="780" data-rawheight="355" class="origin\_image zh-lightbox-thumb" width="780" data-original="https://pic4.zhimg.com/v2-9d6574a67c633d2905fe040a4e9ad17b\_r.jpg"/>

![](https://pic4.zhimg.com/80/v2-9d6574a67c633d2905fe040a4e9ad17b_1440w.webp)

1.2 与使用单个合取式来进行假设表示相比，使用“析合范式”将使得假设空间具有更强的表示能力。若使用最多包含k个合取式的析合范式来表达表1.1西瓜分类问题的假设空间，试估算有多少种可能的假设。
------------------------------------------------------------------------------------------------

答：不包括\*的情况下，单个合取式所能表示的假设有 2×3×3\=182×3×3=182×3×3=18 种。所以在 足够大时，可能的假设有 C180+C181+⋯+C1818\=218C^{0}\_{18}+C\_{18}^1+⋯+C\_{18}^{18}=2^{18}C^{0}\_{18}+C\_{18}^1+⋯+C\_{18}^{18}=2^{18} 种，这是可能假设数的上限。

(1) 首先将西瓜的三个不同属性的特征分别记为(A1,A2),(B1,B2,B3),(C1,C2,C3)。这样西瓜的特征有2×3×3\=182×3×3=182×3×3=18 种不同的组合，我们用一个大小为 2×3×32×3×32×3×3 的二元取值array来表示（后面将其拉直成为一个长度为18的向量），每个位置的取值要么是0要么是1，这18个位置与18种特征组合一一对应。这样就构造出来了一个 2182^{18}2^{18} 的特征空间，只要两个特征对应的18维的向量不同，我们认为是两个不一样的特征；反之两个相同的向量即是相同的特征。

(2) 接着，构造了一个从48种析取范式到18中特征组合的对应函数。48种析取范式的组合为(A1,A2,\*),(B1,B2,B3,\*),(C1,C2,C3,\*)，即 3×4×4\=483×4×4=483×4×4=48 ，其中某个特征取\*值即代表取该特征下所有可能的取值。这个对应函数的思路很清晰，您可以参考下方的代码进行理解。

(3) 最后，就是对从48个析取范式中选出k个进行穷举了！我们对于某k个析取范式转化为的18维向量进行取并操作（对取并后得到的18维向量的某一维的取值，只要这k个向量中对应位置至少有一个值是1，那么该位置的取值就为1，也就是所谓的去除冗余操作），例如(1,1,0,0,…,0)与(1,0,1,0,0,…,0)取并后得到一个新的18维向量是(1,1,1,0,0,0,…,0)。

(4) 我们把取并后得到的18维向量放到一个列表中，而这个18维向量仅仅是我们从48个析取范式中选出了某k个后取并所得到的一个结果！对于48个析取范式选出k个，我们一共可以得到 C48kC\_{48}^kC\_{48}^k 个18维向量。穷举所有组合的可能情况后，我们得到一个 C48kC\_{48}^kC\_{48}^k 大小的列表，其中每个元素都是一个18维的二值向量，对该列表进行去重操作后输出列表长度即为取k值的最终答案，而且这也保证了去重后的列表长度一定在2182^{18}2^{18}以内.

代码：

```python3
import numpy as np
import itertools as it
import time
def get_18(data): #把三维向量变为代表特征组合的18维向量
    a = np.zeros([2,3,3])
    if data[0] == 0:  #对于第一种属性为"*"的情况
        a1 = [1,2]
    else:
        a1 = [data[0]]
    if data[1] == 0:  #对于第二种属性为"*"的情况
        a2 = [1,2,3]
    else:
        a2 = [data[1]]
    if data[2] == 0:  #对于第三种属性为"*"的情况
        a3 = [1,2,3]
    else:
        a3 = [data[2]]
    for m1 in a1:
        for m2 in a2:
            for m3 in a3:
                a[m1-1][m2-1][m3-1] = 1
    a = a.flatten()
    return a           #得到了一个18维向量（0/1二值），代表18种特征组合
def turn_48_to_trible(num):
    # num in [0,47]，把一个小于48的数字对应到一个三维数组中
    i = num//16
    j = num%16//4
    k = num%16%4
    return [i,j,k]
def from_48_to_18(num):  #把0-47的某个数唯一对应到某个18维向量
    data = turn_48_to_trible(num)
    a = get_18(data)
    return a
def main(k):
    hypo_list=[]
    for i in it.combinations(range(48),k):
    #开始对48取k的组合数进行穷举，i是一个k元数组，其中每个元素都是0-47中的某个数，代表(A1,A2,*)(B1,B2,B3,*)(C1,C2,C3,*)的一个组合
        subset = 0
        for j in range(k):
            p = i[j]
            subset = subset | hypo48_oct[p]
        hypo_list.append(subset)
        if len(hypo_list) > 5000000:
            hypo_list = list(set(hypo_list))  #set是集合，是对rset数组进行去重！
            #设置500W上限为了防止set操作时数组长度太长导致程序崩掉
    hypo_list = list(set(hypo_list)) #最终set操作一下得到最终结果
    print("正好包含%d个合取式的析合范式能表示 ： %d 种假设" % (k, len(hypo_list)))
    return(hypo_list)

hypo48 = []
for i in range(48):
    h = from_48_to_18(i)
    hypo48.append(h)
hypo48_oct = []
for hypo in hypo48:
    hypo_bin = '0b'
    for i in hypo:
        hypo_bin = hypo_bin + str(int(i))
    hypo_oct = eval(hypo_bin)
    hypo48_oct.append(hypo_oct)

start = time.time()
hypo_stack = []
for k in range(18):
    k = k+1
    hypo_list = main(k)
    hypo_stack = hypo_stack + hypo_list
    hypo_stack = list(set(hypo_stack))
    end = time.time()
    print( "最多包含%d个合取式的析合范式能表示 ： %d 种假设"%(k,len(hypo_stack)+1))  #加1是因为还有空集这个假设，即不存在好瓜
    print("用时：%.2fs"%(end-start))
```

题目是最多包含k个，所以我把空集假设，即好瓜不存在也算上了。

运行结果：

正好包含1个合取式的析合范式能表示 ： 48 种假设

最多包含1个合取式的析合范式能表示 ： 49 种假设

正好包含2个合取式的析合范式能表示 ： 879 种假设

最多包含2个合取式的析合范式能表示 ： 898 种假设

正好包含3个合取式的析合范式能表示 ： 8223 种假设

最多包含3个合取式的析合范式能表示 ： 8386 种假设

正好包含4个合取式的析合范式能表示 ： 40911 种假设

最多包含4个合取式的析合范式能表示 ： 41743 种假设

正好包含5个合取式的析合范式能表示 ： 112962 种假设

最多包含5个合取式的析合范式能表示 ： 115822 种假设

正好包含6个合取式的析合范式能表示 ： 193998 种假设

最多包含6个合取式的析合范式能表示 ： 201304 种假设

正好包含7个合取式的析合范式能表示 ： 233640 种假设

最多包含7个合取式的析合范式能表示 ： 248854 种假设

正好包含8个合取式的析合范式能表示 ： 233424 种假设

最多包含8个合取式的析合范式能表示 ： 260788 种假设

正好包含9个合取式的析合范式能表示 ： 218394 种假设

最多包含9个合取式的析合范式能表示 ： 262144 种假设

用时：8899.29s

K=9开始，可能的假设应该已经达到上限 218\=2621442^{18}=2621442^{18}=262144，因为需由不包括\*的单个合取式组成的最复杂的假设是\[\[\[1,0,1\]\[0,1,0\]\[1,0,1\]\],\[\[0,1,0\]\[1,0,1\]\[0,1,0\]\]\]或\[\[\[0,1,0\]\[1,0,1\]\[0,1,0\]\],\[\[1,0,1\]\[0,1,0\]\[1,0,1\]\]\]，用立方体的形式画出来就是下面这两种情况（18个方块表示18种基本的假设，红色代表当前析合范式所囊括的假设，即假设向量中为1的位置即为红色，为0即为白色，这个问题其实可以看做上色问题），这两种情况有9个红色方块，无法用带\*的合取式表示，只能由不包括\*的9个合取式组成，在其余任意位置再涂一块都将连成一条边从而能用\*代替。

<img src="https://pic4.zhimg.com/v2-ad7512400832b2e5439c0f47449511e7\_b.jpg" data-caption="" data-size="normal" data-rawwidth="585" data-rawheight="250" class="origin\_image zh-lightbox-thumb" width="585" data-original="https://pic4.zhimg.com/v2-ad7512400832b2e5439c0f47449511e7\_r.jpg"/>

![](https://pic4.zhimg.com/80/v2-ad7512400832b2e5439c0f47449511e7_1440w.webp)

答案主要来自：[https://blog.csdn.net/yuzeyuan12/article/details/83113461](https://link.zhihu.com/?target=https%3A//blog.csdn.net/yuzeyuan12/article/details/83113461)

1.3 若数据包含噪声，则假设空间中有可能不存在与所有训练样本都一致的假设。在此情形下，设计一种归纳偏好用于假设选择。
-----------------------------------------------------------

答：在训练过程中选择满足最多样本的假设。也可以对每个假设，求得其准确率。准确率=(符合假设的条件且为好瓜的样例数量)/(符合假设的条件的样例数量)。选择准确率最高的假设。

另一解答：通常认为两个数据的属性越相近，则更倾向于将他们分为同一类。若相同属性出现了两种不同的分类，则认为它属于与他最临近几个数据的属性。也可以考虑同时去掉所有具有相同属性而不同分类的数据，留下的数据就是没误差的数据，但是可能会丢失部分信息。

1.4 本章1.4节在论述“没有免费的午餐”定理时，默认使用了“分类错误率”作为性能度量来对分类器进行评估。若换用其他性能度量 ，则式（1.1）将改为 Eote(La∣X,f)\=∑h∑x∈χ−X P(x)ℓ(h(x),f(x))P(h∣X,La)E\_{ote } (\\mathfrak{L}\_a∣X,f)=∑\_h∑\_{x∈\\chi-X} P(x)\\ell(h(x),f(x))P(h∣X,\\mathfrak{L}\_a )E\_{ote } (\\mathfrak{L}\_a∣X,f)=∑\_h∑\_{x∈\\chi-X} P(x)\\ell(h(x),f(x))P(h∣X,\\mathfrak{L}\_a ) ，试证明“没有免费的午餐定理”仍成立。
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

∑fEote (La∣X,f)\=∑f∑h∑x∈χ−Xp(x)⋅ℓ(h(x),f(x))⋅p(h∣X,La)\=∑x∈χ−Xp(x)∑hp(h∣X,La)∑fℓ(h(x),f(x))\=∑x∈χ−Xp(x)∑hp(h∣X,La)⋅2|x|−1(ℓ(h(x)\=f(x))+ℓ(h(x)≠f(x)))\=2|x|−1⋅A∑x∈χ−Xp(x)⋅1\\begin{aligned} \\sum\_{f} E\_{\\text {ote }}\\left(\\mathfrak{L}\_{a} \\mid X, f\\right) &=\\sum\_{f} \\sum\_{h} \\sum\_{x \\in \\chi-X} p(x) \\cdot \\ell(h(x), f(x)) \\cdot p\\left(h \\mid X, \\mathfrak{L}\_{a}\\right) \\\\ &=\\sum\_{x \\in \\chi-X} p(x) \\sum\_{h} p\\left(h \\mid X, \\mathfrak{L}\_{a}\\right) \\sum\_{f} \\ell(h(x), f(x)) \\\\ &=\\sum\_{x \\in \\chi-X} p(x) \\sum\_{h} p\\left(h \\mid X, \\mathfrak{L}\_{a}\\right) \\cdot 2^{|x|-1}\\left(\\ell(h(x)=f(x))+\\ell(h(x) \\neq f(x))\\right) \\\\ &=2|x|-1 \\cdot A \\sum\_{x \\in \\chi-X} p(x) \\cdot 1 \\end{aligned}\\begin{aligned} \\sum\_{f} E\_{\\text {ote }}\\left(\\mathfrak{L}\_{a} \\mid X, f\\right) &=\\sum\_{f} \\sum\_{h} \\sum\_{x \\in \\chi-X} p(x) \\cdot \\ell(h(x), f(x)) \\cdot p\\left(h \\mid X, \\mathfrak{L}\_{a}\\right) \\\\ &=\\sum\_{x \\in \\chi-X} p(x) \\sum\_{h} p\\left(h \\mid X, \\mathfrak{L}\_{a}\\right) \\sum\_{f} \\ell(h(x), f(x)) \\\\ &=\\sum\_{x \\in \\chi-X} p(x) \\sum\_{h} p\\left(h \\mid X, \\mathfrak{L}\_{a}\\right) \\cdot 2^{|x|-1}\\left(\\ell(h(x)=f(x))+\\ell(h(x) \\neq f(x))\\right) \\\\ &=2|x|-1 \\cdot A \\sum\_{x \\in \\chi-X} p(x) \\cdot 1 \\end{aligned}

要求性能度量 ℓ\\ell\\ell 满足ℓ(h(x)\=f(x))+ℓ(h(x)≠f(x))\=A\\ell(h(x)=f(x))+\\ell(h(x)≠f(x))=A\\ell(h(x)=f(x))+\\ell(h(x)≠f(x))=A为常数，对于二分类问题，即要求 ℓ(0,0)+ℓ(0,1)\=ℓ(1,1)+ℓ(1,0)\=A\\ell(0,0)+\\ell(0,1)=\\ell(1,1)+\\ell(1,0)=A\\ell(0,0)+\\ell(0,1)=\\ell(1,1)+\\ell(1,0)=A .

1.5\* 试述机器学习能在互联网搜索的哪些环节起作用
---------------------------

1.在向搜索引擎提交信息的阶段，能够从提交文本中进行信息提取，进行语义分析。  
2.在搜索引擎进行信息匹配的阶段，能够提高问题与各个信息的匹配程度。  
3.在向用户展示搜索结果的阶段，能够根据用户对结果感兴趣的程度进行排序。

本文转自 <https://zhuanlan.zhihu.com/p/355235881>，如有侵权，请联系删除。